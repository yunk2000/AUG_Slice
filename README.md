## AUG_Slice

We proposes a code vulnerability detection method based on an augmented program dependency graph and optimized pre-trained models. The approach first extends the program dependency graph to enhance its capacity for capturing code semantics and structural information. Secondly, it utilizes the Code Bidirectional Encoder Representations from Transformers pre-trained model to extract code embedding features and optimizes model performance by introducing weighted cross-entropy loss and Focal Loss to address class imbalance issues. 



### 0. Environment settings

Install necessary dependency libraries: Dependency can be installed with one click through ` requirements. txt `:

```bash
pip install -r requirements.txt
```



### 1. Augmented Program Dependence Graph

1. Firstly, use Joern to parse the source code.
2. `get_cfg_relation_aug.py`: Generate the Control Flow Graph (CFG) and other related information based on the source code data parsed in the previous step.
3. `get_relation.py`: Generate the relevant information of the code scope according to the CFG.
4. `complete_PDG.py`: Obtain the Program Dependence Graph (PDG) based on the source code data parsed in the first step, along with the CFG and other related information.
5. `get_AUGPDG.py`: Generate the Augmented Program Dependence Graph (AUG-PDG) by using the PDG expansion algorithm based on the PDG and related information.



### 2. Program Slicing

1. `access_db_operate.py`: Generate the call graph of the source code.
2. `points_get.py`: Based on the call graph of the source code generated in the previous step and the corresponding vulnerability rules, generate and classify the corresponding candidate vulnerabilities.
3. `extract_df.py`: According to the candidate vulnerabilities obtained in the previous step, use forward slicing and backward slicing techniques to extract slices on the Augmented Program Dependence Graph (AUG-PDG), and combine them with the source code files.
4. `make_label_nvd.py`: Used to obtain the labels of the National Vulnerability Database (NVD) data slices.
5. `make_label_sard.py`: Used to obtain the labels of the Software Assurance Reference Dataset (SARD) data slices.
6. `data_preprocess.py`: Write the corresponding labels of the slices into the slice code files.
7. `data_process.py`: Perform formatting processing on the slice files.



### 3. Code Embedding and Classification

1. `codebert_aug.py`: The file for code embedding and classification.





#### Note

We have provided the slice files generated by us.

The code in this paper refers to https://github.com/SySeVR/SySeVR.git







